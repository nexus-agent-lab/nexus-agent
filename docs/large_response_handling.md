# Adaptive Data Bridge Architecture

## Problem
- MCP è¿”å› 821 ä¸ªå®ä½“ â†’ Context çˆ†ç‚¸
- æœ¬åœ° LLM context å° + æ…¢ â†’ æ— æ³•å¤„ç†
- äº‘ç«¯ LLM context å¤§ + å¿« â†’ å¯ä»¥å¤„ç†
- å½“å‰åšæ³•ä¸é€šç”¨ï¼Œéœ€è¦æ™ºèƒ½é€‚é…

---

## æ ¸å¿ƒè®¾è®¡: Intelligent MCP Proxy (Prod Ready)

### 1. æ ¸å¿ƒæµç¨‹ï¼šOff-Loader pattern

```mermaid
sequenceDiagram
    participant LLM as Nexus Brain
    participant Proxy as MCP Middleware
    participant Redis as Cache / State
    participant Sandbox as Data Volume
    participant MCP as Home Assistant

    LLM->>Proxy: list_entities()
    
    rect rgb(240, 248, 255)
        Note over Proxy, Redis: 1. Cache Check
        Proxy->>Redis: GET mcp:list_entities:hash
        alt Cache Hit
            Redis-->>Proxy: Cached Data
            Proxy-->>LLM: Return Data
        end
    end

    Proxy->>MCP: Call Tool
    MCP-->>Proxy: Huge JSON (2MB)

    rect rgb(255, 240, 245)
        Note over Proxy, Sandbox: 2. Data Governance
        alt Size > 10KB
            Proxy->>Sandbox: Save to /data/uuid.json
            Proxy-->>LLM: SYSTEM ALERT: Data Offloaded (use python_sandbox)
            
            Note right of LLM: 3. Code Gen
            LLM->>LLM: Write Python Filter Code
            LLM->>Sandbox: Execute Code
            Sandbox-->>LLM: Small Filtered Result
        else Size < 10KB
            Proxy-->>LLM: Return JSON Directly
        end
    end
```

### 2. å¢å¼ºè®¾è®¡ (Gap Analysis)

#### A. Schema Awareness (Schema æ„ŸçŸ¥)
**é—®é¢˜**: å¦‚æœ LLM ä¸çŸ¥é“ JSON ç»“æ„ï¼Œå®ƒå†™ä¸å‡ºè¿‡æ»¤ä»£ç ã€‚
**è§£æ³•**: Proxy åœ¨æ‹¦æˆªæ•°æ®çš„åŒæ—¶ï¼Œå¿…é¡»**æå–å¹¶è¿”å› Schema æ ·ä¾‹**ã€‚
*   Middleware é€»è¾‘ï¼šæˆªå–å‰ 2 æ¡æ•°æ®ï¼Œç”Ÿæˆ `preview`ã€‚
*   Prompt æç¤ºä¼˜åŒ–ï¼š
    > "Data saved to `file.json`. Here is a **PREVIEW of the first 2 items**: `[{'id': '...', 'state': '...'}]`. Please write code based on this structure."

#### B. Auto-Cleanup (è‡ªåŠ¨åƒåœ¾å›æ”¶)
**é—®é¢˜**: `/data/` ç›®å½•ä¼šå †æ»¡ä¸´æ—¶æ–‡ä»¶ã€‚
**è§£æ³•**:
*   File TTL: æ¯ä¸ªä¸´æ—¶æ–‡ä»¶å‘½åæºå¸¦æ—¶é—´æˆ³ï¼Œæˆ–è€…ç”±åå°ä»»åŠ¡ `cron` æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡ (> 1å°æ—¶çš„æ–‡ä»¶)ã€‚
*   Volatile Volume: å®¹å™¨é‡å¯è‡ªåŠ¨æ¸…ç©ºã€‚

#### C. Smart Semantic Routing (è¯­ä¹‰è·¯ç”± - é«˜çº§)
**é—®é¢˜**: ç”¨æˆ·é—® "å®¢å…æ¸©åº¦"ï¼ŒLLM å¯èƒ½è¿˜åœ¨ç”¨ `list_entities` ï¼ˆç¬¨ï¼‰ã€‚
**è§£æ³•**: Vector Store ä»‹å…¥ã€‚
*   Proxy å¯ä»¥åœ¨åå°å¼‚æ­¥æŠŠ `list_entities` çš„ç»“æœ Embedding åˆ°å‘é‡åº“ã€‚
*   ä¸‹æ¬¡ç›´æ¥æä¾› `semantic_search_entities` å·¥å…·ã€‚

#### D. Security (æ•°æ®å®‰å…¨)
**é—®é¢˜**: æ²™ç®±ä»£ç å¯èƒ½è¯»å–ä¸è¯¥è¯»çš„æ–‡ä»¶ã€‚
**è§£æ³•**:
*   **Chroot**: æ²™ç®±åªèƒ½è®¿é—® `/data/sandbox/`ã€‚
*   **User Isolation**: æ¯ä¸ªä¼šè¯ï¼ˆSessionï¼‰æ‹¥æœ‰ç‹¬ç«‹çš„å­ç›®å½• `/data/session_id/`ï¼Œé˜²æ­¢è·¨ä¼šè¯æ•°æ®æ³„éœ²ã€‚

---

### Implementation Plan (Next Steps)

1.  **Core Middleware**: å®ç° `MCPMiddleware` ç±» (Cache + Offloader)ã€‚
2.  **Integration**: åœ¨ `agent.py` ä¸­æ³¨å…¥ Middlewareã€‚
3.  **Sandbox Update**: ç¡®ä¿ `python_sandbox` å·¥å…·èƒ½è®¿é—®å…±äº«å·ã€‚


```python
async def adaptive_tool_output(tool_name, result, model_type):
    MAX_LOCAL = 4000   # ~1K tokens for local
    MAX_CLOUD = 50000  # ~12K tokens for cloud
    
    threshold = MAX_CLOUD if model_type == "cloud" else MAX_LOCAL
    
    if len(result) <= threshold:
        return result  # ç›´æ¥è¿”å›
    else:
        return await smart_reduce(tool_name, result)
```

### 2. Smart Reduce Strategies

**Strategy A: Summary + Data ID (ç¼“å­˜)**
```python
# å­˜å…¥ä¸´æ—¶ç¼“å­˜ï¼Œç»™ LLM ä¸€ä¸ª ID
data_id = cache.store(result)
summary = f"Found {count} entities. Use `filter_data(data_id='{data_id}', query='...')` to search."
return summary
```

**Strategy B: LLM å†™ Python è¿‡æ»¤ä»£ç **
```python
# Prompt LLM ç”Ÿæˆè¿‡æ»¤ä»£ç 
prompt = f"æ•°æ®å¤ªå¤§ ({len(result)} chars)ã€‚è¯·å†™ä¸€æ®µ Python ä»£ç æ¥è¿‡æ»¤å‡ºä¸ç”¨æˆ·é—®é¢˜ç›¸å…³çš„éƒ¨åˆ†ã€‚"
filter_code = await llm.invoke(prompt)

# åœ¨æ²™ç®±ä¸­æ‰§è¡Œ
filtered = await sandbox.run(filter_code, data=result)
return filtered
```

**Strategy C: é¢„å®šä¹‰è¿‡æ»¤å™¨**
```python
# æ ¹æ® tool_name é€‰æ‹©é¢„å®šä¹‰è¿‡æ»¤å™¨
if tool_name == "list_entities":
    # åªè¿”å›å‰ 50 ä¸ª + é¢†åŸŸç»Ÿè®¡
    domains = group_by_domain(result)
    summary = f"Domains: {domains}\nSample: {result[:50]}"
    return summary
```

---

## å®ç°æ–¹æ¡ˆ

### Phase 1: å¿«é€Ÿå®ç° (ä»Šå¤©)

åœ¨ `agent.py` çš„ `tool_node_with_permissions` ä¸­æ·»åŠ :

```python
# åœ¨ tool æ‰§è¡Œå
result_str = str(prediction)

# Adaptive Bridge
if len(result_str) > CONTEXT_LIMIT:
    # åˆ¤æ–­æ¨¡å‹ç±»å‹
    is_cloud = "glm" in llm_model or "deepseek" in llm_model
    
    if is_cloud:
        # äº‘ç«¯æ¨¡å‹å¯ä»¥å¤„ç†ï¼Œä½†ä¹Ÿåšä¸ªä¸Šé™
        result_str = result_str[:50000] + "\n[Truncated for safety]"
    else:
        # æœ¬åœ°æ¨¡å‹éœ€è¦æ¿€è¿›å‹ç¼©
        result_str = smart_summarize(tool_name, result_str)
```

### Phase 2: Cache + Filter Tool (æœªæ¥)

1. æ·»åŠ  `filter_cached_data(data_id, query)` å·¥å…·
2. å¤§æ•°æ®è‡ªåŠ¨ç¼“å­˜å¹¶è¿”å› ID
3. LLM å¯ä»¥å¤šæ¬¡è°ƒç”¨ filter ç›´åˆ°æ‰¾åˆ°ç›®æ ‡

### Phase 3: LLM Self-Filter (é«˜çº§)

1. æ£€æµ‹åˆ°å¤§æ•°æ®æ—¶ï¼Œæç¤º LLM ç”Ÿæˆè¿‡æ»¤ä»£ç 
2. ä½¿ç”¨ `python_sandbox` æ‰§è¡Œè¿‡æ»¤
3. è¿”å›è¿‡æ»¤åçš„å°æ•°æ®é›†

---

## å®ç°ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | å¤æ‚åº¦ |
|--------|------|--------|
| ğŸ”´ P0 | Phase 1: åŸºç¡€æˆªæ–­ + æ¨¡å‹æ„ŸçŸ¥ | 10 min |
| ğŸŸ¡ P1 | Phase 2: Cache + Filter Tool | 1 hr |
| ğŸŸ¢ P2 | Phase 3: LLM Self-Filter | 2 hr |

---

## ç”¨æˆ·ç¡®è®¤

éœ€è¦æˆ‘ç°åœ¨å®ç° **Phase 1** å—ï¼Ÿè¿™å°†ç«‹å³è§£å†³æœ¬åœ°æ¨¡å‹çš„ context é—®é¢˜ã€‚
